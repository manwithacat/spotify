{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for ML\n",
    "\n",
    "This notebook prepares the cleaned dataset for machine learning by:\n",
    "1. Loading the cleaned Parquet data\n",
    "2. Creating ML-ready features\n",
    "3. Encoding categorical variables\n",
    "4. Scaling numeric features\n",
    "5. Saving processed data ready for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from Parquet (faster and more efficient)\n",
    "df = pd.read_parquet('../data/processed/cleaned_spotify_data.parquet')\n",
    "\n",
    "print(f\"Dataset loaded: {df.shape}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Target and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable: popularity (regression) or popularity_category (classification)\n",
    "TARGET_VARIABLE = 'popularity'  # Change to 'popularity_category' for classification\n",
    "\n",
    "# Features to exclude from modeling\n",
    "EXCLUDE_FEATURES = [\n",
    "    'Unnamed: 0',  # Index column\n",
    "    'track_id',    # Identifier\n",
    "    'track_name',  # Identifier\n",
    "    'album_name',  # High cardinality\n",
    "    'artists',     # High cardinality\n",
    "    'popularity',  # Target (if doing classification)\n",
    "    'popularity_category',  # Derived from target\n",
    "]\n",
    "\n",
    "print(f\"Target variable: {TARGET_VARIABLE}\")\n",
    "print(f\"Target distribution:\")\n",
    "if TARGET_VARIABLE == 'popularity':\n",
    "    print(df[TARGET_VARIABLE].describe())\n",
    "else:\n",
    "    print(df[TARGET_VARIABLE].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection and Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for feature engineering\n",
    "df_ml = df.copy()\n",
    "\n",
    "# Audio features (already normalized 0-1)\n",
    "audio_features = ['danceability', 'energy', 'valence', 'acousticness', \n",
    "                  'instrumentalness', 'speechiness', 'liveness']\n",
    "\n",
    "# Numeric features that need scaling\n",
    "numeric_features = ['duration_ms', 'loudness', 'tempo', 'duration_min']\n",
    "\n",
    "# Categorical features\n",
    "categorical_features = ['explicit', 'key', 'mode', 'time_signature', \n",
    "                       'track_genre', 'mood_energy', 'energy_category', 'tempo_category']\n",
    "\n",
    "print(f\"Audio features: {len(audio_features)}\")\n",
    "print(f\"Numeric features: {len(numeric_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature interactions\n",
    "df_ml['energy_danceability'] = df_ml['energy'] * df_ml['danceability']\n",
    "df_ml['valence_energy'] = df_ml['valence'] * df_ml['energy']\n",
    "df_ml['acousticness_energy'] = df_ml['acousticness'] * df_ml['energy']\n",
    "\n",
    "# Polynomial features for key audio metrics\n",
    "df_ml['energy_squared'] = df_ml['energy'] ** 2\n",
    "df_ml['danceability_squared'] = df_ml['danceability'] ** 2\n",
    "df_ml['valence_squared'] = df_ml['valence'] ** 2\n",
    "\n",
    "# Duration categories\n",
    "df_ml['is_short_track'] = (df_ml['duration_min'] < 3).astype(int)\n",
    "df_ml['is_long_track'] = (df_ml['duration_min'] > 5).astype(int)\n",
    "\n",
    "# Energy + valence combinations (mood indicators)\n",
    "df_ml['high_energy_happy'] = ((df_ml['energy'] > 0.7) & (df_ml['valence'] > 0.7)).astype(int)\n",
    "df_ml['low_energy_sad'] = ((df_ml['energy'] < 0.3) & (df_ml['valence'] < 0.3)).astype(int)\n",
    "\n",
    "# Add new features to numeric list\n",
    "interaction_features = ['energy_danceability', 'valence_energy', 'acousticness_energy',\n",
    "                       'energy_squared', 'danceability_squared', 'valence_squared',\n",
    "                       'is_short_track', 'is_long_track', 'high_energy_happy', 'low_energy_sad']\n",
    "\n",
    "print(f\"Created {len(interaction_features)} interaction features\")\n",
    "print(f\"Total features before encoding: {len(df_ml.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary encoding for explicit\n",
    "df_ml['explicit'] = df_ml['explicit'].astype(int)\n",
    "\n",
    "# One-hot encode low-cardinality categoricals\n",
    "low_cardinality = ['mode', 'time_signature', 'mood_energy', 'energy_category', 'tempo_category']\n",
    "\n",
    "for col in low_cardinality:\n",
    "    if col in df_ml.columns:\n",
    "        dummies = pd.get_dummies(df_ml[col], prefix=col, drop_first=True)\n",
    "        df_ml = pd.concat([df_ml, dummies], axis=1)\n",
    "        df_ml.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# Label encode track_genre (high cardinality)\n",
    "if 'track_genre' in df_ml.columns:\n",
    "    le_genre = LabelEncoder()\n",
    "    df_ml['track_genre_encoded'] = le_genre.fit_transform(df_ml['track_genre'])\n",
    "    df_ml.drop('track_genre', axis=1, inplace=True)\n",
    "    print(f\"Encoded {len(le_genre.classes_)} unique genres\")\n",
    "\n",
    "# Label encode key (musical key)\n",
    "if 'key' in df_ml.columns:\n",
    "    # Key is already numeric (0-11), so just keep it\n",
    "    pass\n",
    "\n",
    "print(f\"Total features after encoding: {len(df_ml.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Scale Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features that need scaling (not already 0-1)\n",
    "features_to_scale = ['duration_ms', 'loudness', 'tempo', 'duration_min', 'track_genre_encoded', 'key']\n",
    "features_to_scale = [f for f in features_to_scale if f in df_ml.columns]\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform\n",
    "df_ml[features_to_scale] = scaler.fit_transform(df_ml[features_to_scale])\n",
    "\n",
    "print(f\"Scaled {len(features_to_scale)} features\")\n",
    "print(f\"Scaled features: {features_to_scale}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prepare Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove excluded features\n",
    "features_to_drop = [col for col in EXCLUDE_FEATURES if col in df_ml.columns]\n",
    "df_ml.drop(columns=features_to_drop, inplace=True)\n",
    "\n",
    "# Separate features and target\n",
    "if TARGET_VARIABLE in df_ml.columns:\n",
    "    y = df_ml[TARGET_VARIABLE]\n",
    "    X = df_ml.drop(TARGET_VARIABLE, axis=1)\n",
    "else:\n",
    "    # Target was already excluded, use original df\n",
    "    y = df[TARGET_VARIABLE]\n",
    "    X = df_ml\n",
    "\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "print(f\"\\nFeature columns ({len(X.columns)}):\")\n",
    "print(list(X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y if TARGET_VARIABLE == 'popularity_category' else None\n",
    ")\n",
    "\n",
    "print(\"Train-Test Split:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"  y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "import os\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Save as Parquet (efficient for ML)\n",
    "X_train.to_parquet('../data/processed/X_train.parquet', index=False)\n",
    "X_test.to_parquet('../data/processed/X_test.parquet', index=False)\n",
    "y_train.to_frame().to_parquet('../data/processed/y_train.parquet', index=False)\n",
    "y_test.to_frame().to_parquet('../data/processed/y_test.parquet', index=False)\n",
    "\n",
    "# Also save full processed dataset\n",
    "df_ml_full = pd.concat([X, y], axis=1)\n",
    "df_ml_full.to_parquet('../data/processed/ml_ready_data.parquet', index=False)\n",
    "\n",
    "print(\"✅ Saved processed data:\")\n",
    "print(\"  - X_train.parquet\")\n",
    "print(\"  - X_test.parquet\")\n",
    "print(\"  - y_train.parquet\")\n",
    "print(\"  - y_test.parquet\")\n",
    "print(\"  - ml_ready_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Feature Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature information\n",
    "feature_info = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'dtype': X.dtypes.values,\n",
    "    'missing': X.isnull().sum().values,\n",
    "    'unique': X.nunique().values,\n",
    "    'mean': X.mean().values if TARGET_VARIABLE == 'popularity' else [np.nan] * len(X.columns),\n",
    "    'std': X.std().values if TARGET_VARIABLE == 'popularity' else [np.nan] * len(X.columns)\n",
    "})\n",
    "\n",
    "feature_info.to_csv('../data/processed/feature_info.csv', index=False)\n",
    "print(\"✅ Saved feature_info.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE ENGINEERING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total features: {len(X.columns)}\")\n",
    "print(f\"Training samples: {len(X_train):,}\")\n",
    "print(f\"Test samples: {len(X_test):,}\")\n",
    "print(f\"Target variable: {TARGET_VARIABLE}\")\n",
    "print(\"\\nData ready for machine learning!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature info\n",
    "feature_info.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
